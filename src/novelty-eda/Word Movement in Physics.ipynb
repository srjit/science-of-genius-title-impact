{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../code-previous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sklearn.feature_extraction as skfeatures\n",
    "import time\n",
    "import os\n",
    "\n",
    "import operator\n",
    "\n",
    "import string\n",
    "import swifter\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='sreejith_s', api_key='rcet0rTqFCc3WeOzWTjv')\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "from unicodedata import category\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/mnt/disks/vault/analysis-data/interdisciplinary-novelty-analysis/all_discipline_data.pql\"\n",
    "data = pd.read_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_labels = ['Physics, Applied',\n",
    "                  'Physics, Fluids & Plasmas',\n",
    "                  'Physics, Atomic, Molecular & Chemical',\n",
    "                  'Physics, Multidisciplinary',\n",
    "                  'Physics, Condensed Matter',\n",
    "                  'Physics, Nuclear',\n",
    "                  'Physics, Particles & Fields',\n",
    "                  'Physics, Mathematical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_data = data[data[\"Label\"].isin(physics_labels)]\n",
    "article_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_applied_phy = physics_data[physics_data.Label == \"Physics, Applied\"]\n",
    "physics_applied_phy = physics_applied_phy.sort_values(by=\"PubYear\")\n",
    "vectorizer1 = CountVectorizer()\n",
    "vectorized_words1 = vectorizer1.fit_transform(physics_applied_phy.title_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_counts = physics_applied_phy.groupby('PubYear').size().reset_index(name=\"count\")\n",
    "counts =  list(row_counts[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "vocab = vectorizer1.vocabulary_\n",
    "rev_vocab = {index:word for word,index in vocab.items()}\n",
    "# Highest Frequency words all time\n",
    "all_time_word_frequencies = vectorized_words1.sum(axis=0).reshape(-1,).tolist()[0]\n",
    "word_index_with_freq = {index:freq for index,freq in enumerate(all_time_word_frequencies)}\n",
    "\n",
    "word_with_freq = {rev_vocab[index]:np.log(freq + 1) for index, freq in word_index_with_freq.items()}\n",
    "\n",
    "sorted_word_with_freq = sorted(word_with_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "top_words_all_corpus = pd.DataFrame(list(sorted_word_with_freq[:N]), columns=[\"word\",\"frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(top_words_all_corpus[\"word\"])\n",
    "\n",
    "## laser, electron, quantum, carbon, nanoparticles, \n",
    "## semiconductor, spectroscopy, superconducting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_counts = physics_applied_phy.groupby('PubYear').size().reset_index(name=\"count\")\n",
    "counts =  list(row_counts[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a9dbcff44116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mindex_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorized_words1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0myearly_word_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "words = ['laser', 'electron', 'quantum', 'carbon', 'nanoparticles', \n",
    "         'semiconductor', 'spectroscopy', 'superconducting']\n",
    "\n",
    "\n",
    "frequencies = []\n",
    "\n",
    "for word in words:\n",
    "    word_index = vocab[word]\n",
    "    counts = []\n",
    "    index_start = 0\n",
    "    for i in range(len(row_counts)):\n",
    "        offset = index_start + counts[i]\n",
    "        tmp = vectorized_words1[index_start:offset,:]\n",
    "        yearly_word_freq = tmp.sum(axis=0).reshape(-1,).tolist()[0][word_index]\n",
    "        \n",
    "        counts.append(yearly_word_freq)\n",
    "        index_start = offset\n",
    "    \n",
    "    frequencies.append(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

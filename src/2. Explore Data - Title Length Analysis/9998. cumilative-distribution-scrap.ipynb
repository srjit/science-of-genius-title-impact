{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../code-previous\")\n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sklearn.feature_extraction as skfeatures\n",
    "import utils\n",
    "import time\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "from unicodedata import category\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "path2rawdata = '/mnt/disks/vault/wos2017-parsed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = \"/mnt/disks/vault/analysis-data/raw_data_full/raw_data_full.pql\"\n",
    "data = pd.read_pickle(raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 738469/738469 [00:01<00:00, 455362.84it/s]\n",
      "Progress: 100%|██████████| 738469/738469 [00:00<00:00, 810732.63it/s]\n",
      "Progress: 100%|██████████| 738469/738469 [00:01<00:00, 545517.83it/s]\n",
      "Progress: 100%|██████████| 738469/738469 [00:12<00:00, 57854.29it/s]\n",
      "Progress: 100%|██████████| 738469/738469 [00:15<00:00, 48799.24it/s]\n",
      "Progress: 100%|██████████| 738469/738469 [00:01<00:00, 533458.86it/s]\n",
      "Progress: 100%|██████████| 738469/738469 [00:01<00:00, 598999.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# New fields to dataframe \n",
    "data['log_c5'] = data['c5'].progress_apply(lambda x: np.log(x+1))\n",
    "data['character_count'] = data['Title'].progress_apply(lambda x: len(x))\n",
    "data[\"word_count\"] = data[\"Title\"].progress_apply(lambda x: len(x.split()))\n",
    "data['title_without_punct'] = data['Title'].progress_apply(lambda x: \n",
    "                                                           str.lower(''.join(ch for ch in str(x) if category(ch)[0] != 'P')))\n",
    "data[\"title_without_stopwords\"] = data['title_without_punct'].progress_apply(lambda x: \n",
    "                                                                            \" \".join([word for word in x.split() if word not in stopwords]))\n",
    "\n",
    "\n",
    "data[\"word_count\"] = data[\"Title\"].progress_apply(lambda x: len(x.split()))\n",
    "data[\"cleaned_title_word_count\"] = data[\"title_without_stopwords\"].progress_apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tmp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-04792c4d775e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# cumilative distributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word_count_cum_sum\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rank_cum_sum\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tmp' is not defined"
     ]
    }
   ],
   "source": [
    "# cumilative distributions\n",
    "tmp[\"word_count_cum_sum\"] = tmp['word_count'].cumsum()\n",
    "tmp[\"rank_cum_sum\"] = tmp['rank'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint distribution between title word count and the rank\n",
    "g = sns.jointplot(\"word_count\", \"rank\", data=tmp, kind=\"hex\", color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutual Information of the joint distribution of rank and character count\n",
    "\n",
    "from sklearn.metrics import mutual_info_score\n",
    "MI_title_without_stopwords_rank = mutual_info_score(tmp[\"character_count\"], tmp[\"rank\"])\n",
    "MI_wordcount_rank = mutual_info_score(tmp[\"word_count\"], tmp[\"rank\"])\n",
    "MI_charactercount_rank = mutual_info_score(tmp[\"character_count\"], tmp[\"rank\"])\n",
    "\n",
    "print(\"Title without stop & Rank:\", MI_title_without_stopwords_rank)\n",
    "print(\"WordCount & Rank:\", MI_wordcount_rank)\n",
    "print(\"Charcater count & Rank:\", MI_charactercount_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = tmp[[\"c5\", \"word_count\"]]\n",
    "_tmp.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = tmp[[\"c5\",\"character_count\"]]\n",
    "_tmp.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# too dependent on the random state\n",
    "\n",
    "\n",
    "from yellowbrick.target import FeatureCorrelation\n",
    "\n",
    "feature_names = ['character_count', 'word_count', 'cleaned_title_word_count']\n",
    "X,y = tmp[feature_names],tmp['c5']\n",
    "visualizer = FeatureCorrelation(method='mutual_info-regression',\n",
    "                                labels=np.array(feature_names))\n",
    "\n",
    "discrete_features = [False for _ in range(len(feature_names))]\n",
    "visualizer.fit(X, y, discrete_features=discrete_features, random_state=20)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

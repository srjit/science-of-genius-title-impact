{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "> \u001b[0;32m<ipython-input-8-b53696bddcff>\u001b[0m(6)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      4 \u001b[0;31m\u001b[0mtfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 6 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m    \u001b[0munique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../code-previous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sklearn.feature_extraction as skfeatures\n",
    "import time\n",
    "import os\n",
    "\n",
    "import operator\n",
    "import pickle\n",
    "import string\n",
    "import swifter\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='sreejith_s', api_key='rcet0rTqFCc3WeOzWTjv')\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "from unicodedata import category\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/mnt/disks/vault/analysis-data/word-journey/all-data.pql\"\n",
    "\n",
    "#data_path = \"/mnt/disks/vault/analysis-data/interdisciplinary-novelty-analysis/physics.pql\"\n",
    "data = pd.read_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "disciplines = [\"Architecture\",\"Art\",\"Humanities, Multidisciplinary\",\"Folklore\",\"Medieval & Renaissance Studies\",\"Asian Studies\",\"Classics\",\"Dance\",\"Film, Radio, Television\",\"History\",\"History & Philosophy of Science\",\"Literary Theory & Criticism\",\"Literary Reviews\",\"Literature\",\"Literature, African, Australian, Canadian\",\"Literature, American\",\"Literature, British Isles\",\"Literature, German, Dutch, Scandinavian\",\"Literature, Romance\",\"Literature, Slavic\",\"Poetry\",\"Music\",\"Philosophy\",\"Religion\",\"Theater\",\"Agriculture, Dairy & Animal Science\",\"Agricultural Engineering\",\"Agricultural Economics & Policy\",\"Agriculture, Multidisciplinary\",\"Agronomy\",\"Horticulture\",\"Soil Science\",\"Allergy\",\"Anatomy & Morphology\",\"Anesthesiology\",\"Anthropology\",\"Audiology & Speech-Language Pathology\",\"Behavioral Sciences\",\"Biochemical Research Methods\",\"Biochemistry & Molecular Biology\",\"Biodiversity Conservation\",\"Biophysics\",\"Biotechnology & Applied Microbiology\",\"Cardiac & Cardiovascular Systems\",\"Peripheral Vascular Disease\",\"Cell & Tissue Engineering\",\"Cell Biology\",\"Dentistry, Oral Surgery & Medicine\",\"Dermatology\",\"Developmental Biology\",\"Emergency Medicine\",\"Andrology\",\"Endocrinology & Metabolism\",\"Entomology\",\"Ecology\",\"Environmental Sciences\",\"Environmental Studies\",\"Evolutionary Biology\",\"Fisheries\",\"Food Science & Technology\",\"Forestry\",\"Gastroenterology & Hepatology\",\"Critical Care Medicine\",\"Primary Health Care\",\"Medicine, General & Internal\",\"Genetics & Heredity\",\"Geriatrics & Gerontology\",\"Gerontology\",\"Health Care Sciences & Services\",\"Health Policy & Services\",\"Hematology\",\"Immunology\",\"Infectious Diseases\",\"Integrative & Complementary Medicine\",\"Medicine, Legal\",\"Biology\",\"Limnology\",\"Marine & Freshwater Biology\",\"Mathematical & Computational Biology\",\"Medical Ethics\",\"Medical Informatics\",\"Medical Laboratory Technology\",\"Microbiology\",\"Mycology\",\"Clinical Neurology\",\"Neurosciences\",\"Neuroimaging\",\"Nursing\",\"Nutrition & Dietetics\",\"Obstetrics & Gynecology\",\"Oncology\",\"Ophthalmology\",\"Orthopedics\",\"Otorhinolaryngology\",\"Paleontology\",\"Parasitology\",\"Pathology\",\"Pediatrics\",\"Chemistry, Medicinal\",\"Pharmacology & Pharmacy\",\"Physiology\",\"Plant Sciences\",\"Psychiatry\",\"Public, Environmental & Occupational Health\",\"Radiology, Nuclear Medicine & Medical Imaging\",\"Rehabilitation\",\"Reproductive Biology\",\"Medicine, Research & Experimental\",\"Respiratory System\",\"Rheumatology\",\"Sport Sciences\",\"Substance Abuse\",\"Surgery\",\"Toxicology\",\"Transplantation\",\"Tropical Medicine\",\"Urology & Nephrology\",\"Veterinary Sciences\",\"Virology\",\"Ornithology\",\"Zoology\",\"Astronomy & Astrophysics\",\"Chemistry, Applied\",\"Chemistry, Multidisciplinary\",\"Chemistry, Analytical\",\"Chemistry, Inorganic & Nuclear\",\"Chemistry, Organic\",\"Chemistry, Physical\",\"Crystallography\",\"Electrochemistry\",\"Geochemistry & Geophysics\",\"Geology\",\"Geosciences, Multidisciplinary\",\"Mathematics, Applied\",\"Mathematics, Interdisciplinary Applications\",\"Mathematics\",\"Statistics & Probability\",\"Meteorology & Atmospheric Sciences\",\"Mineralogy\",\"Mining & Mineral Processing\",\"Oceanography\",\"Optics\",\"Geography, Physical\",\"Physics, Applied\",\"Physics, Fluids & Plasmas\",\"Physics, Atomic, Molecular & Chemical\",\"Physics, Multidisciplinary\",\"Physics, Condensed Matter\",\"Physics, Nuclear\",\"Physics, Particles & Fields\",\"Physics, Mathematical\",\"Polymer Science\",\"Thermodynamics\",\"Water Resources\",\"Nanoscience & Nanotechnology\",\"Logic\",\"Multidisciplinary Sciences\",\"Acoustics\",\"Automation & Control Systems\",\"Computer Science, Artificial Intelligence\",\"Computer Science, Cybernetics\",\"Computer Science, Hardware & Architecture\",\"Computer Science, Information Systems\",\"Computer Science, Interdisciplinary Applications\",\"Computer Science, Software Engineering\",\"Computer Science, Theory & Methods\",\"Construction & Building Technology\",\"Energy & Fuels\",\"Engineering, Aerospace\",\"Engineering, Multidisciplinary\",\"Engineering, Biomedical\",\"Engineering, Environmental\",\"Engineering, Chemical\",\"Engineering, Industrial\",\"Engineering, Manufacturing\",\"Engineering, Marine\",\"Engineering, Civil\",\"Engineering, Ocean\",\"Engineering, Petroleum\",\"Engineering, Electrical & Electronic\",\"Engineering, Mechanical\",\"Engineering, Geological\",\"Ergonomics\",\"Imaging Science & Photographic Technology\",\"Information Science & Library Science\",\"Instruments & Instrumentation\",\"Materials Science, Paper & Wood\",\"Materials Science, Ceramics\",\"Materials Science, Multidisciplinary\",\"Materials Science, Biomaterials\",\"Materials Science, Characterization & Testing\",\"Materials Science, Coatings & Films\",\"Materials Science, Composites\",\"Materials Science, Textiles\",\"Mechanics\",\"Metallurgy & Metallurgical Engineering\",\"Microscopy\",\"Nuclear Science & Technology\",\"Operations Research & Management Science\",\"Remote Sensing\",\"Robotics\",\"Spectroscopy\",\"Telecommunications\",\"Transportation\",\"Transportation Science & Technology\",\"Archaeology\",\"Area Studies\",\"Social Sciences, Biomedical\",\"Business\",\"Business, Finance\",\"Economics\",\"Industrial Relations & Labor\",\"Management\",\"Communication\",\"Criminology & Penology\",\"Cultural Studies\",\"Demography\",\"Education & Educational Research\",\"Education, Scientific Disciplines\",\"Education, Special\",\"Ethnic Studies\",\"Family Studies\",\"Geography\",\"Law\",\"Political Science\",\"International Relations\",\"Linguistics\",\"Language & Linguistics\",\"Social Sciences, Mathematical Methods\",\"Psychology, Biological\",\"Psychology, Clinical\",\"Psychology, Educational\",\"Psychology, Developmental\",\"Psychology, Applied\",\"Psychology\",\"Psychology, Multidisciplinary\",\"Psychology, Psychoanalysis\",\"Psychology, Mathematical\",\"Psychology, Experimental\",\"Psychology, Social\",\"Planning & Development\",\"Public Administration\",\"Social Issues\",\"Ethics\",\"History of Social Sciences\",\"Hospitality, Leisure, Sport & Tourism\",\"Social Sciences, Interdisciplinary\",\"Social Work\",\"Sociology\",\"Urban Studies\",\"Women's Studies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.Label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c676e4426a91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_grouped_by_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"title_without_stopwords\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title_without_stopwords\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_grouped_by_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_grouped_by_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data_grouped_by_label = data[[\"Label\",\"title_without_stopwords\"]].groupby(data.Label)[\"title_without_stopwords\"].apply(list)\n",
    "data_grouped_by_label = pd.DataFrame(data_grouped_by_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 249/249 [00:23<00:00, 10.46it/s]\n"
     ]
    }
   ],
   "source": [
    "data_grouped_by_label[\"title_words\"] = data_grouped_by_label[\"title_without_stopwords\"].progress_apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_without_stopwords</th>\n",
       "      <th>title_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Acoustics</th>\n",
       "      <td>[multiplexer using flat exponential filters, m...</td>\n",
       "      <td>multiplexer using flat exponential filters mul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agricultural Economics &amp; Policy</th>\n",
       "      <td>[poultry eggs, accounting commodity credit cor...</td>\n",
       "      <td>poultry eggs accounting commodity credit corpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agricultural Engineering</th>\n",
       "      <td>[soft energy from palm wastes, potential land ...</td>\n",
       "      <td>soft energy from palm wastes potential land di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agriculture, Dairy &amp; Animal Science</th>\n",
       "      <td>[collection 2 cell embryos their culture media...</td>\n",
       "      <td>collection 2 cell embryos their culture media ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agriculture, Multidisciplinary</th>\n",
       "      <td>[response strawberry fruit yield plant populat...</td>\n",
       "      <td>response strawberry fruit yield plant populati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               title_without_stopwords  \\\n",
       "Label                                                                                    \n",
       "Acoustics                            [multiplexer using flat exponential filters, m...   \n",
       "Agricultural Economics & Policy      [poultry eggs, accounting commodity credit cor...   \n",
       "Agricultural Engineering             [soft energy from palm wastes, potential land ...   \n",
       "Agriculture, Dairy & Animal Science  [collection 2 cell embryos their culture media...   \n",
       "Agriculture, Multidisciplinary       [response strawberry fruit yield plant populat...   \n",
       "\n",
       "                                                                           title_words  \n",
       "Label                                                                                   \n",
       "Acoustics                            multiplexer using flat exponential filters mul...  \n",
       "Agricultural Economics & Policy      poultry eggs accounting commodity credit corpo...  \n",
       "Agricultural Engineering             soft energy from palm wastes potential land di...  \n",
       "Agriculture, Dairy & Animal Science  collection 2 cell embryos their culture media ...  \n",
       "Agriculture, Multidisciplinary       response strawberry fruit yield plant populati...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_grouped_by_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/mnt/disks/vault/analysis-data/interdisciplinary-novelty-analysis/word_selection_entropy\"\n",
    "\n",
    "# pickle_out = open(folder + \"/data_grouped_by_label.pickle\",\"wb\")\n",
    "# pickle.dump(data_grouped_by_label, pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "\n",
    "with open(folder + \"/data_grouped_by_label.pickle\", 'rb') as f:\n",
    "    data_grouped_by_label = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(min_df=1, max_df=1.0)\n",
    "# vectorized_words = vectorizer.fit_transform(data_grouped_by_label.title_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/mnt/disks/vault/analysis-data/interdisciplinary-novelty-analysis/word_selection_entropy\"\n",
    "\n",
    "# pickle_out = open(folder + \"/vectorizer.pickle\",\"wb\")\n",
    "# pickle.dump(vectorizer, pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "# pickle_out = open(folder + \"/vectorized_words.pickle\",\"wb\")\n",
    "# pickle.dump(vectorized_words, pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "\n",
    "with open(folder + \"/vectorizer.pickle\", 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "    \n",
    "with open(folder + \"/vectorized_words.pickle\", 'rb') as f:\n",
    "    vectorized_words = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vocab = {value:key for key,value in vectorizer.vocabulary_.items()}\n",
    "count_rev_dict = {value:key for key,value in vectorizer.vocabulary_.items()}\n",
    "words = [count_rev_dict[i] for i in range(len(vectorizer.vocabulary_.keys()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Iterate through the columns of the vectorized words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_frequency_counter = {}\n",
    "\n",
    "# pxs = []\n",
    "\n",
    "# def foo(l):\n",
    "    \n",
    "\n",
    "\n",
    "# for idx in tqdm(range(vectorized_words.shape[1])):\n",
    "#     px = np.sum(np.bincount(vectorized_words[:,idx:idx+1].toarray().flatten())/vectorized_words.shape[0])\n",
    "#     pxs.append(px)\n",
    "    \n",
    "    #word_frequency_counter[words[idx]] = dict(Counter(np.reshape(frequencies, (1,len(frequencies)))[0]))\n",
    "    #unique, counts = np.bincount(frequencies, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19201972/can-numpy-bincount-work-with-2d-arrays\n",
    "\n",
    "idx = 0\n",
    "a = vectorized_words.transpose()\n",
    "b = a.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,  15,   3,  12,   0,   2,   0,   4,   2,   0,   0,\n",
       "          0,   0,   0, 390,   0,   4,   4],\n",
       "       [ 14,   3,   5,  39,  20,  55,  20,  12,   0, 110, 232, 112,   0,\n",
       "          6,   2,   0, 196,   4,  42,  22],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  32,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:10, :20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2401230, 249)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(b[:10, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493947"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 5000\n",
    "limit = np.amax(b) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_unique, _b, _c, _unique_counts = np.unique(b[:1], return_index=True, return_inverse=True, return_counts=True, axis=0)\n",
    "\n",
    "# from collections import Counter\n",
    "# Counter(_a[0])\n",
    "\n",
    "# This is returning the unique rows\n",
    "_unique_counts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Testing with a small sample of b__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 7522.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.442783312158676, 2.76162571219778, 0.1985152433458726, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# first 10 rows and 20 columns of b\n",
    "tmp = b[:10, :20]\n",
    "\n",
    "uniques = []\n",
    "counts = []\n",
    "entropies = []\n",
    "tfs = []\n",
    "\n",
    "for i in tqdm(range(tmp.shape[0])):\n",
    "\n",
    "    unique, _counts = np.unique(tmp[i], return_counts=True)\n",
    "    \n",
    "    uniques.append(unique)\n",
    "    counts.append(_counts)\n",
    "    \n",
    "    qcs = _counts/tmp.shape[1]\n",
    "    ln_qcs = np.log(qcs)\n",
    "    \n",
    "    entropy = -1 * sum(qcs * ln_qcs)   \n",
    "    entropies.append(entropy)\n",
    "\n",
    "print(entropies)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calculating entropies for every word from the vectorizer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2401230/2401230 [01:14<00:00, 32042.68it/s]\n"
     ]
    }
   ],
   "source": [
    "uniques = []\n",
    "counts = []\n",
    "entropies = []\n",
    "tfs = []\n",
    "\n",
    "Nc = float(b.shape[1])\n",
    "\n",
    "for i in tqdm(range(b.shape[0])):\n",
    "    \n",
    "    unique, _counts = np.unique(b[i], return_counts=True)\n",
    "    \n",
    "    uniques.append(unique)\n",
    "    counts.append(_counts)\n",
    "    \n",
    "    qcs = _counts[_counts>0]/Nc\n",
    "    ln_qcs = np.log(qcs)\n",
    "    \n",
    "    entropy = -1 * np.sum(qcs * ln_qcs)   \n",
    "    entropies.append(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2401230"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entropies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term frequencies\n",
    "term_frequencies = vectorized_words.sum(axis=0).reshape(-1,).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205623"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([(index, freq) for index,freq in enumerate(term_frequencies) if freq>50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_words_with_indices = [(index, freq) for index,freq in enumerate(term_frequencies) if freq>50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_word_tfs = [np.log(freq) for (index,freq) in good_words_with_indices]\n",
    "good_indices = [index for index, freq in good_words_with_indices]\n",
    "good_word_entropies = [entropies[index] for index in good_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205623"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_word_entropies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plotting entropy to term frequency__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/plotly/plotly/plotly.py:230: UserWarning:\n",
      "\n",
      "Woah there! Look at all those points! Due to browser limitations, the Plotly SVG drawing functions have a hard time graphing more than 500k data points for line charts, or 40k points for other types of charts. Here are some suggestions:\n",
      "(1) Use the `plotly.graph_objs.Scattergl` trace object to generate a WebGl graph.\n",
      "(2) Trying using the image API to return an image instead of a graph URL\n",
      "(3) Use matplotlib\n",
      "(4) See if you can create your visualization with fewer data points\n",
      "\n",
      "If the visualization you're using aggregates points (e.g., box plot, histogram, etc.) you can disregard this warning.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/plotly/plotly/plotly.py:230: UserWarning:\n",
      "\n",
      "Woah there! Look at all those points! Due to browser limitations, the Plotly SVG drawing functions have a hard time graphing more than 500k data points for line charts, or 40k points for other types of charts. Here are some suggestions:\n",
      "(1) Use the `plotly.graph_objs.Scattergl` trace object to generate a WebGl graph.\n",
      "(2) Trying using the image API to return an image instead of a graph URL\n",
      "(3) Use matplotlib\n",
      "(4) See if you can create your visualization with fewer data points\n",
      "\n",
      "If the visualization you're using aggregates points (e.g., box plot, histogram, etc.) you can disregard this warning.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/plotly/plotly/plotly.py:230: UserWarning:\n",
      "\n",
      "Woah there! Look at all those points! Due to browser limitations, the Plotly SVG drawing functions have a hard time graphing more than 500k data points for line charts, or 40k points for other types of charts. Here are some suggestions:\n",
      "(1) Use the `plotly.graph_objs.Scattergl` trace object to generate a WebGl graph.\n",
      "(2) Trying using the image API to return an image instead of a graph URL\n",
      "(3) Use matplotlib\n",
      "(4) See if you can create your visualization with fewer data points\n",
      "\n",
      "If the visualization you're using aggregates points (e.g., box plot, histogram, etc.) you can disregard this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The draw time for this plot will be slow for all clients.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/plotly/api/v1/clientresp.py:40: UserWarning:\n",
      "\n",
      "Estimated Draw Time Too Long\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/IPython/core/display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~sreejith_s/172.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace0 = go.Scatter(\n",
    "    x = good_word_entropies,\n",
    "    y = good_word_tfs,\n",
    "    mode = 'markers',\n",
    "    text = words,\n",
    "    marker = dict(\n",
    "        color = '#FFBAD2',\n",
    "        line = dict(width = 1)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "layout= go.Layout(\n",
    "    title= 'Entropy - Tf plot',\n",
    "    hovermode= 'closest',\n",
    "    xaxis= dict(\n",
    "        title= 'Entropy',\n",
    "        ticklen= 5,\n",
    "        zeroline= False,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title= 'Term Frequency',\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    \n",
    "    showlegend= False\n",
    ")\n",
    "\n",
    "plotdata = [trace0]\n",
    "\n",
    "\n",
    "fig= go.Figure(data=plotdata, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

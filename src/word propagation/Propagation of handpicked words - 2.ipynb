{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../code-previous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "import peakutils\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "from plotly import tools\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='sreejith_s', api_key='rcet0rTqFCc3WeOzWTjv')\n",
    "\n",
    "from unicodedata import category\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "picked_words = ['2mass','andromedae','anosov','antiquark','artinian','aurigae','auslander','baryogenesis','baryonic','beurling','birational','blazar','blazars','branes','braneworld','brst','cabibbo','calabi','capsulorhexis','cassiopeiae','cepheids','chevalley','cobordism','cocycles','compactified','dilatonic','dilepton','diphoton','diquark','disolvate','eclogites','efirov','eiscat','ethyleniques','fastbus','floer','glueball','grassmannians','gravitino','harnack','hecke','heegaard','hemisolvate','herbig','hinode','horava','hyades','hyers','hypoelliptic','inflaton','interlibrary','iridotomy','iwasawa','izuchenie','jona','kislot','kisloty','koszul','krull','lasinio','lectotypification','leptogenesis','lusztig','markarian','metabelian','metapelites','motivic','nannofossil','neutralino','nonleptonic','ogle','ophiuchi','opredeleniya','orbifold','orionis','os3','paleointensity','parallaxes','pbarp','pegasi','persei','ph2pch2pph2','phosphido','pomeron','ppbar','profinite','proizvodnykh','protostars','protostellar','puppis','qsos','quarkonia','quarkonium','quivers','radiat','rayet','rcvs','reaktsii','rectopexy','reggeon','rhic','rhytidectomy','riphean','sacrocolpopexy','sasakian','scuti','seiberg','semileptonic','shimura','sintez','smpte','stratotype','subducted','subducting','subdwarf','sundrum','sunyaev','supergiants','suzaku','threefolds','triebel','ultraluminous','urol','ursae','voprosu','vzaimodeistvie','zumino']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/mnt/disks/vault/analysis-data/word-journey/all-data.pql\"\n",
    "data = pd.read_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped_by_label = data[[\"Label\",\"title_without_stopwords\"]].groupby(data.Label)[\"title_without_stopwords\"].apply(list)\n",
    "data_grouped_by_label = pd.DataFrame(data_grouped_by_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data grouped by label into disk\n",
    "\n",
    "# filename = \"/mnt/disks/vault/analysis-data/word-journey/all-data-grouped-by-label.pql\"\n",
    "# pickle_out = open(filename,\"wb\")\n",
    "# pickle.dump(data_grouped_by_label, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_in = open(\"/mnt/disks/vault/analysis-data/word-journey/vectorizer.pickle\",\"rb\")\n",
    "# vectorizer = pickle.load(pickle_in)\n",
    "\n",
    "# pickle_in = open(\"/mnt/disks/vault/analysis-data/word-journey/vectorized_words.pickle\",\"rb\")\n",
    "# vectorized_words = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-171e1719ce87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcount_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcount_rev_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcount_rev_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "count_vocab = {value:key for key,value in vectorizer.vocabulary_.items()}\n",
    "count_rev_dict = {value:key for key,value in vectorizer.vocabulary_.items()}\n",
    "words = [count_rev_dict[i] for i in range(len(vectorizer.vocabulary_.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_wordarray = vectorized_words.toarray()\n",
    "document_frequency = (vectorized_wordarray != 0).sum(0).tolist()\n",
    "document_frequency_log =  [np.log(x) for x in document_frequency]\n",
    "#2. Term Frequency - Number of times in which a word appears in a document\n",
    "term_frequency = vectorized_words.sum(axis=0).reshape(-1,).tolist()[0]\n",
    "term_frequency_log = [np.log(x) for x in term_frequency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what disciplines does the word appear in?\n",
    "\n",
    "word_ = \"nannofossil\"\n",
    "\n",
    "index = words.index(word_)\n",
    "count_rev_dict[index]\n",
    "counts = vectorized_wordarray[:,index]\n",
    "\n",
    "discipline_indices = [discipline_index for discipline_index in range(len(counts.tolist())) if counts[discipline_index] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disciplines = [list(data_grouped_by_label.index)[index] for index in discipline_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = []\n",
    "\n",
    "for discipline in disciplines:\n",
    "    filtered_data.append(data[data.Label == discipline])\n",
    "    \n",
    "#data = None    \n",
    "\n",
    "frequencies = []\n",
    "\n",
    "for data_ in filtered_data:\n",
    "    \n",
    "    data_ = data_.sort_values(by=\"PubYear\")\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorized_words = vectorizer.fit_transform(data_.title_without_stopwords)\n",
    "    \n",
    "    vocab = vectorizer.vocabulary_\n",
    "    rev_vocab = {index:word for word,index in vocab.items()}\n",
    "    \n",
    "    row_counts = data_.groupby('PubYear').size().reset_index(name=\"count\")\n",
    "    counts =  list(row_counts[\"count\"])\n",
    "    \n",
    "    word_index = vocab[word_]\n",
    "    yearly_freq_for_word = []\n",
    "    index_start = 0\n",
    "    \n",
    "    for i in range(len(row_counts)):\n",
    "        \n",
    "        offset = index_start + counts[i]\n",
    "        tmp = vectorized_words[index_start:offset,:]\n",
    "        yearly_word_freq = tmp.sum(axis=0).reshape(-1,).tolist()[0][word_index]\n",
    "        \n",
    "        ## Normalizing - Divide by number of physics articles in the year\n",
    "        _tmp = float(yearly_word_freq) / counts[i]\n",
    "        \n",
    "        yearly_freq_for_word.append(_tmp)\n",
    "        index_start = offset\n",
    "        \n",
    "    frequencies.append(yearly_freq_for_word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "years = [sorted(_data.PubYear.unique()) for _data in filtered_data]\n",
    "\n",
    "\n",
    "datatoplot = [go.Scatter(\n",
    "            x=years[0],\n",
    "            y=frequencies[0],\n",
    "            mode='lines',\n",
    "            name=disciplines[0],\n",
    "            marker=dict(\n",
    "                color='#800000'\n",
    "            )\n",
    "    ),go.Scatter(\n",
    "            x=years[1],\n",
    "            y=frequencies[1],\n",
    "            mode='lines',\n",
    "            name=disciplines[1],\n",
    "            marker=dict(\n",
    "                color='#9A6324'\n",
    "            )\n",
    "    ),go.Scatter(\n",
    "            x=years[2],\n",
    "            y=frequencies[2],\n",
    "            mode='lines',\n",
    "            name=disciplines[2],\n",
    "            marker=dict(\n",
    "                color='#808000'\n",
    "            )\n",
    "    ),go.Scatter(\n",
    "            x=years[3],\n",
    "            y=frequencies[3],\n",
    "            mode='lines',\n",
    "            name=disciplines[3],\n",
    "            marker=dict(\n",
    "                color='#469990'\n",
    "            )\n",
    "    ),go.Scatter(\n",
    "            x=years[4],\n",
    "            y=frequencies[4],\n",
    "            mode='lines',\n",
    "            name=disciplines[4],\n",
    "            marker=dict(\n",
    "                color='#000075'\n",
    "            )\n",
    "    ),go.Scatter(\n",
    "            x=years[5],\n",
    "            y=frequencies[5],\n",
    "            mode='lines',\n",
    "            name=disciplines[5],\n",
    "            marker=dict(\n",
    "                color='#000000'\n",
    "            )\n",
    "    ),go.Scatter(\n",
    "            x=years[6],\n",
    "            y=frequencies[6],\n",
    "            mode='lines',\n",
    "            name=disciplines[6],\n",
    "            marker=dict(\n",
    "                color='#e6194B'\n",
    "            )\n",
    "    ),go.Scatter(\n",
    "            x=years[7],\n",
    "            y=frequencies[7],\n",
    "            mode='lines',\n",
    "            name=disciplines[7],\n",
    "            marker=dict(\n",
    "                color='#f58231'\n",
    "            ),\n",
    "    ),go.Scatter(\n",
    "            x=years[8],\n",
    "            y=frequencies[8],\n",
    "            mode='lines',\n",
    "            name=disciplines[8],\n",
    "            marker=dict(\n",
    "                color='#ffe119'\n",
    "            )\n",
    "    ),go.Scatter(\n",
    "            x=years[9],\n",
    "            y=frequencies[9],\n",
    "            mode='lines',\n",
    "            name=disciplines[9],\n",
    "            marker=dict(\n",
    "                color='#bfef45'\n",
    "            )\n",
    "    ),go.Scatter(\n",
    "            x=years[10],\n",
    "            y=frequencies[10],\n",
    "            mode='lines',\n",
    "            name=disciplines[10],\n",
    "            marker=dict(\n",
    "                color='#3cb44b'\n",
    "            )\n",
    "    ),go.Scatter(\n",
    "            x=years[11],\n",
    "            y=frequencies[11],\n",
    "            mode='lines',\n",
    "            name=disciplines[11],\n",
    "            marker=dict(\n",
    "                color='#42d4f4'\n",
    "            )\n",
    "    )]\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Word Propagation ' + word_,\n",
    "    \n",
    "    xaxis=dict(\n",
    "        title='Year',\n",
    "        titlefont=dict(\n",
    "            family='Lato',\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Popularity Ratio',\n",
    "        titlefont=dict(\n",
    "            family='Lato',\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "fig1 = go.Figure(data=datatoplot, layout=layout)\n",
    "py.iplot(fig1, filename='freq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Frequently observed pattern: One of the disciplines picks it up and it goes up. examples - neutron, nanofossil__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(frequencies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [sorted(_data.PubYear.unique()) for _data in filtered_data]\n",
    "\n",
    "indices1 = peakutils.indexes(frequencies[0], thres=2e-4/max(frequencies[0]), min_dist=0.1)\n",
    "indices2 = peakutils.indexes(frequencies[9], thres=2e-4/max(frequencies[9]), min_dist=0.1)\n",
    "   \n",
    "    \n",
    "datatoplot = [go.Scatter(\n",
    "            x=years[0],\n",
    "            y=frequencies[0],\n",
    "            mode='lines+markers',\n",
    "            name=disciplines[0],\n",
    "            marker=dict(\n",
    "                color='#800000'\n",
    "            )\n",
    "    ), go.Scatter(\n",
    "    x=[years[0][i] for i in indices1],\n",
    "    y=[frequencies[0][j] for j in indices1],\n",
    "    mode='markers',\n",
    "    name=disciplines[0] + \" peaks\",\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color='rgb(255,0,0)',\n",
    "        symbol='cross'\n",
    "    )),go.Scatter(\n",
    "            x=years[9],\n",
    "            y=frequencies[9],\n",
    "            mode='lines',\n",
    "            name=disciplines[9],\n",
    "            marker=dict(\n",
    "                color='#9A6324'\n",
    "            )\n",
    "    ),go.Scatter(\n",
    "    x=[years[9][i] for i in indices2],\n",
    "    y=[frequencies[9][j] for j in indices2],\n",
    "    mode='markers',\n",
    "    name=disciplines[9] + \" peaks\",\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color='#ffe119',\n",
    "        symbol='cross'\n",
    "    ))\n",
    "            \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig1 = go.Figure(data=datatoplot, layout=layout)\n",
    "py.iplot(fig1, filename='freq')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

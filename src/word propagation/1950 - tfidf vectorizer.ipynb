{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../code-previous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sklearn.feature_extraction as skfeatures\n",
    "import time\n",
    "import os\n",
    "\n",
    "import operator\n",
    "\n",
    "import string\n",
    "import swifter\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "from plotly import tools\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username='sreejith_s', api_key='rcet0rTqFCc3WeOzWTjv')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "from unicodedata import category\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/mnt/disks/vault/analysis-data/interdisciplinary-novelty-analysis/all_discipline_data.pql\"\n",
    "data = pd.read_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data50 = data[data.PubYear == 1950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data50_group = data50[[\"Label\",\"title_without_stopwords\"]].groupby(data50.Label)[\"title_without_stopwords\"].apply(list)\n",
    "\n",
    "data50_group = pd.DataFrame(data50_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data50_group[\"title_words\"] = data50_group[\"title_without_stopwords\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_without_stopwords    [diffraction pattern circular aperture measure...\n",
       "title_words                diffraction pattern circular aperture measured...\n",
       "Name: Physics, Applied, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data50_group.iloc[449]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data50_group.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples 613\n",
      "num_features 23816\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorizer = TfidfVectorizer(use_idf=True, min_df=5, stop_words='english')\n",
    "# tf_idf_matrix = vectorizer.fit_transform(data50_group.title_words)\n",
    "\n",
    "# num_samples, num_features = tf_idf_matrix.shape\n",
    "# print(\"num_samples\", num_samples)\n",
    "# print(\"num_features\", num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=2, max_df=1.0)\n",
    "vectorized_words = vectorizer.fit_transform(data50_group.title_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Document Frequency - Number of disciplines in which the word has appeared\n",
    "\n",
    "vectorized_wordarray = vectorized_words.toarray()\n",
    "document_frequency = (vectorized_wordarray != 0).sum(0).tolist()\n",
    "document_frequency_log =  [np.log(x) for x in document_frequency]\n",
    "#2. Term Frequency - Number of times in which a word appears in a document\n",
    "term_frequency = vectorized_words.sum(axis=0).reshape(-1,).tolist()[0]\n",
    "term_frequency_log = [np.log(x) for x in term_frequency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vocab = {value:key for key,value in vectorizer.vocabulary_.items()}\n",
    "count_rev_dict = {value:key for key,value in vectorizer.vocabulary_.items()}\n",
    "words = [count_rev_dict[i] for i in range(len(vectorizer.vocabulary_.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_idf_vocab = {value:key for key,value in vectorizer.vocabulary_}\n",
    "#tf_idf_vocab\n",
    "#tfidf_rev_dict = {value:key for key,value in vectorizer.vocabulary_.items()}\n",
    "#words = [tfidf_rev_dict[i] for i in range(len(vectorizer.idf_))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/plotly/plotly/plotly.py:230: UserWarning:\n",
      "\n",
      "Woah there! Look at all those points! Due to browser limitations, the Plotly SVG drawing functions have a hard time graphing more than 500k data points for line charts, or 40k points for other types of charts. Here are some suggestions:\n",
      "(1) Use the `plotly.graph_objs.Scattergl` trace object to generate a WebGl graph.\n",
      "(2) Trying using the image API to return an image instead of a graph URL\n",
      "(3) Use matplotlib\n",
      "(4) See if you can create your visualization with fewer data points\n",
      "\n",
      "If the visualization you're using aggregates points (e.g., box plot, histogram, etc.) you can disregard this warning.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/plotly/plotly/plotly.py:230: UserWarning:\n",
      "\n",
      "Woah there! Look at all those points! Due to browser limitations, the Plotly SVG drawing functions have a hard time graphing more than 500k data points for line charts, or 40k points for other types of charts. Here are some suggestions:\n",
      "(1) Use the `plotly.graph_objs.Scattergl` trace object to generate a WebGl graph.\n",
      "(2) Trying using the image API to return an image instead of a graph URL\n",
      "(3) Use matplotlib\n",
      "(4) See if you can create your visualization with fewer data points\n",
      "\n",
      "If the visualization you're using aggregates points (e.g., box plot, histogram, etc.) you can disregard this warning.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/plotly/plotly/plotly.py:230: UserWarning:\n",
      "\n",
      "Woah there! Look at all those points! Due to browser limitations, the Plotly SVG drawing functions have a hard time graphing more than 500k data points for line charts, or 40k points for other types of charts. Here are some suggestions:\n",
      "(1) Use the `plotly.graph_objs.Scattergl` trace object to generate a WebGl graph.\n",
      "(2) Trying using the image API to return an image instead of a graph URL\n",
      "(3) Use matplotlib\n",
      "(4) See if you can create your visualization with fewer data points\n",
      "\n",
      "If the visualization you're using aggregates points (e.g., box plot, histogram, etc.) you can disregard this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The draw time for this plot will be slow for clients without much RAM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/plotly/api/v1/clientresp.py:40: UserWarning:\n",
      "\n",
      "Estimated Draw Time Slow\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/IPython/core/display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~sreejith_s/106.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider one discipline - Applied Physics index 449\n",
    "\n",
    "# get tf scores of all the words of applied physics\n",
    "#tf_applied_physics = tf_idf_matrix[450:451,:].todense().reshape(-1,).tolist()[0]\n",
    "#idf_words = vectorizer.idf_\n",
    "\n",
    "#tf_idf_physics = [(tf_applied_physics[i], idf_words[i]) for i in range(len(idf_words))]\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x = document_frequency_log,\n",
    "    y = term_frequency_log,\n",
    "    mode = 'markers',\n",
    "    text = words,\n",
    "    marker = dict(\n",
    "        color = '#FFBAD2',\n",
    "        line = dict(width = 1)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "layout= go.Layout(\n",
    "    title= 'Document Frequency - Term Frequency plot ',\n",
    "    hovermode= 'closest',\n",
    "    xaxis= dict(\n",
    "        title= 'Log Document Frequency (Number of disciplines in which the word occurs)',\n",
    "        ticklen= 5,\n",
    "        zeroline= False,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title= 'Log Term Frequency (Count of the word in corpus)',\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    \n",
    "    showlegend= False\n",
    ")\n",
    "\n",
    "plotdata = [trace0]\n",
    "\n",
    "\n",
    "fig= go.Figure(data=plotdata, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us pick a couple of \"good\" words (words which occur in multiple disciplines and are whose log tf are not too high) for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Words:  neutron, influenza, ketones, protons, tuberculin__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which all disciples have neutron in them ?\n",
    "# lets find the indices\n",
    "\n",
    "\n",
    "# index of the word - \n",
    "index = 37037\n",
    "words.index(\"neutron\")\n",
    "count_rev_dict[index]\n",
    "counts = vectorized_wordarray[:,index]\n",
    "\n",
    "discipline_indices = [discipline_index for discipline_index in range(len(counts.tolist())) if counts[discipline_index] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Which disciplines are those?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chemistry',\n",
       " 'Chemistry, Multidisciplinary',\n",
       " 'Chemistry, Physical',\n",
       " 'Instruments & Instrumentation',\n",
       " 'Life Sciences & Biomedicine',\n",
       " 'Multidisciplinary Sciences',\n",
       " 'Physical Sciences',\n",
       " 'Physics',\n",
       " 'Physics, Applied',\n",
       " 'Physics, Atomic, Molecular & Chemical',\n",
       " 'Physics, Multidisciplinary',\n",
       " 'Physics, Nuclear',\n",
       " 'Radiology, Nuclear Medicine & Medical Imaging',\n",
       " 'Science & Technology',\n",
       " 'Science & Technology - Other Topics',\n",
       " 'Technology']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(data50_group.index)[index] for index in discipline_indices]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
